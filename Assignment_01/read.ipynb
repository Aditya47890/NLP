{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac34f03a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m reader \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenized_hindi.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100000\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1013\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilepath_or_buffer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msep\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m-> 1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   1016\u001b[0m     delim_whitespace,\n\u001b[0;32m   1017\u001b[0m     engine,\n\u001b[0;32m   1018\u001b[0m     sep,\n\u001b[0;32m   1019\u001b[0m     on_bad_lines,\n\u001b[0;32m   1020\u001b[0m     names,\n\u001b[0;32m   1021\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:2226\u001b[0m, in \u001b[0;36m_refine_defaults_read\u001b[1;34m(dialect, delimiter, delim_whitespace, engine, sep, on_bad_lines, names, defaults, dtype_backend)\u001b[0m\n\u001b[0;32m   2220\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2221\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecified a delimiter with both sep and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2222\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelim_whitespace=True; you can only specify one.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2223\u001b[0m     )\n\u001b[0;32m   2225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m delimiter \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 2226\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2227\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecified \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mn as separator or delimiter. This forces the python engine \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2228\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhich does not accept a line terminator. Hence it is not allowed to use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2229\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe line terminator as separator.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2230\u001b[0m     )\n\u001b[0;32m   2232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m delimiter \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   2233\u001b[0m     \u001b[38;5;66;03m# assign default separator value\u001b[39;00m\n\u001b[0;32m   2234\u001b[0m     kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m delim_default\n",
      "\u001b[1;31mValueError\u001b[0m: Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "reader = pd.read_csv(\"tokenized_hindi.txt\", chunksize=100000, sep=\"\\n\", header=None)\n",
    "\n",
    "# for chunk in reader:\n",
    "#     process(chunk)  # or store, write, analyze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6caf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "                                  tokenized_sentence\n",
      "0  इनेलो  1987 में  उस  वक्त  ऐसे  ही  दोराहे  पर...\n",
      "1  हालांकि  तब  पार्टी  पर  देवीलाल  की  मजबूत  प...\n",
      "2  1989 में  देवीलाल  केन्द्र  की  राजनीति  में  ...\n",
      "3  उन  परिस्थितियों  में  देवीलाल  ने  कड़ा  निर्...\n",
      "4  उस  समय  रणजीत  की  नाराजगी  के  चलते  उनके  स...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import islice\n",
    "\n",
    "# File path\n",
    "file_path = \"C:\\\\Users\\\\adity\\\\Desktop\\\\NLP\\\\tokenized_hindi.txt\"\n",
    "\n",
    "# Number of lines to read\n",
    "num_lines = 500_000\n",
    "\n",
    "# Read 5 lakh lines into a DataFrame\n",
    "with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n",
    "    lines = list(islice(file, num_lines))\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(lines, columns=[\"tokenized_sentence\"])\n",
    "\n",
    "# Strip any leading/trailing whitespace\n",
    "df[\"tokenized_sentence\"] = df[\"tokenized_sentence\"].str.strip()\n",
    "\n",
    "print(\"Done\")\n",
    "# Show preview\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee2a41c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of                                        tokenized_sentence\n",
       "0       इनेलो  1987 में  उस  वक्त  ऐसे  ही  दोराहे  पर...\n",
       "1       हालांकि  तब  पार्टी  पर  देवीलाल  की  मजबूत  प...\n",
       "2       1989 में  देवीलाल  केन्द्र  की  राजनीति  में  ...\n",
       "3       उन  परिस्थितियों  में  देवीलाल  ने  कड़ा  निर्...\n",
       "4       उस  समय  रणजीत  की  नाराजगी  के  चलते  उनके  स...\n",
       "...                                                   ...\n",
       "499995  मोहम्मद  फवाद  फारूख  खान  जेएन  मेडिकल  कॉलेज...\n",
       "499996  वे  अपने  परिवार  के  साथ  मंजूरगढ़ी  के  पाम ...\n",
       "499997   उनके  भाई  भी  मेडिकल  क्षेत्र  से  जुड़े  हैं ।\n",
       "499998  मोहम्मद  फवाद  का  कहना  है  कि  उनकी  सोसायटी...\n",
       "499999  लोगों  को  लगता  है  कि  उनके  जरिए  सोसायटी  ...\n",
       "\n",
       "[500000 rows x 1 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0389ac9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500000 entries, 0 to 499999\n",
      "Data columns (total 2 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   tokenized_sentence  500000 non-null  object\n",
      " 1   tokens              500000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbe6346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenized_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>455839</th>\n",
       "      <td>पहले  पक्ष  का  आरोप  है  कि  पुलिस  ने  पकड़े ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172211</th>\n",
       "      <td>फेल्प्स  ने  टूर्नामेंट  में  तीसरी  बार  यह  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381296</th>\n",
       "      <td>अक्टूबर  के  महीने  में  आपकी  योजनाओं  को  आक...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420611</th>\n",
       "      <td>बैठक  में  जनकल्याणकारी  योजनाओं  के  क्रियान्...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17994</th>\n",
       "      <td>ii .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80889</th>\n",
       "      <td>कार्यसमिति  में  बरकरार  रहने  वालों  में  राह...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103799</th>\n",
       "      <td>बुधवार  सुबह  चार  बजे  मकान  के  एक  हिस्से  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187648</th>\n",
       "      <td>मुठभेड़  में  तस्करों  और  पुलिस  की  तरफ  कई  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317243</th>\n",
       "      <td>बगावत  के  तुरंत  बाद  वे  पांच  विधायकों  के ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184405</th>\n",
       "      <td>वह  आपको  आपके  दोस्तों , परिवार  के  साथ  वक्...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375555</th>\n",
       "      <td>इसके  अलावा  प्रत्यक्ष  कर  कानून  को  सरल  बन...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498558</th>\n",
       "      <td>अभियुक्त  विकास  दुबे  एवं  उसके  साथियों  के ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46061</th>\n",
       "      <td>राहुकाल: प्रात: ९.०</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121255</th>\n",
       "      <td>यह  करो  क्योंकि  तुम  इसे  प्यार  करते  हो , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92989</th>\n",
       "      <td>यह  तो  जनता  ही  बताएगी  लेकिन  उनके  समर्थक ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439632</th>\n",
       "      <td>भोपाल  डेली  हिंदी  न्‍ यूज़) ।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141515</th>\n",
       "      <td>डॉ .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458794</th>\n",
       "      <td>भोपाल ।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107668</th>\n",
       "      <td>और  इसी  सूची  में  दुनिया  के  नेताओं  की  सू...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>आर्चर  ऐसे  ही  खिलाड़ी  हैं .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201633</th>\n",
       "      <td>पुलिस  ने  सभी  छात्र  प्रदर्शनारियों  को  करन...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420318</th>\n",
       "      <td>बताया  जा  रहा  है  कि  द्रोणाचार्य  अवॉर्ड  स...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119708</th>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455097</th>\n",
       "      <td>करछना  थाना  के  लोहदी  गांव  निवासी  महेन्द्र...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425043</th>\n",
       "      <td>ये  छात्र  बिहार  में  पटना , गया , समस्तीपुर ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       tokenized_sentence\n",
       "455839  पहले  पक्ष  का  आरोप  है  कि  पुलिस  ने  पकड़े ...\n",
       "172211  फेल्प्स  ने  टूर्नामेंट  में  तीसरी  बार  यह  ...\n",
       "381296  अक्टूबर  के  महीने  में  आपकी  योजनाओं  को  आक...\n",
       "420611  बैठक  में  जनकल्याणकारी  योजनाओं  के  क्रियान्...\n",
       "17994                                                ii .\n",
       "80889   कार्यसमिति  में  बरकरार  रहने  वालों  में  राह...\n",
       "103799  बुधवार  सुबह  चार  बजे  मकान  के  एक  हिस्से  ...\n",
       "187648  मुठभेड़  में  तस्करों  और  पुलिस  की  तरफ  कई  ...\n",
       "317243  बगावत  के  तुरंत  बाद  वे  पांच  विधायकों  के ...\n",
       "184405  वह  आपको  आपके  दोस्तों , परिवार  के  साथ  वक्...\n",
       "375555  इसके  अलावा  प्रत्यक्ष  कर  कानून  को  सरल  बन...\n",
       "498558  अभियुक्त  विकास  दुबे  एवं  उसके  साथियों  के ...\n",
       "46061                                 राहुकाल: प्रात: ९.०\n",
       "121255  यह  करो  क्योंकि  तुम  इसे  प्यार  करते  हो , ...\n",
       "92989   यह  तो  जनता  ही  बताएगी  लेकिन  उनके  समर्थक ...\n",
       "439632                    भोपाल  डेली  हिंदी  न्‍ यूज़) ।\n",
       "141515                                               डॉ .\n",
       "458794                                            भोपाल ।\n",
       "107668  और  इसी  सूची  में  दुनिया  के  नेताओं  की  सू...\n",
       "2099                       आर्चर  ऐसे  ही  खिलाड़ी  हैं .\n",
       "201633  पुलिस  ने  सभी  छात्र  प्रदर्शनारियों  को  करन...\n",
       "420318  बताया  जा  रहा  है  कि  द्रोणाचार्य  अवॉर्ड  स...\n",
       "119708                                                  .\n",
       "455097  करछना  थाना  के  लोहदी  गांव  निवासी  महेन्द्र...\n",
       "425043  ये  छात्र  बिहार  में  पटना , गया , समस्तीपुर ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacfe901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Statistics:\n",
      "1. Total Sentences: 500000\n",
      "2. Total Words: 9474163\n",
      "3. Total Characters: 35303216\n",
      "4. Average Sentence Length: 18.95 words/sentence\n",
      "5. Average Word Length: 3.73 characters/word\n",
      "6. Type/Token Ratio (TTR): 0.0216\n"
     ]
    }
   ],
   "source": [
    "# Convert all sentences into lists of words\n",
    "df[\"tokens\"] = df[\"tokenized_sentence\"].str.split()\n",
    "\n",
    "# i. Total number of sentences\n",
    "total_sentences = len(df)\n",
    "\n",
    "# ii. Total number of words\n",
    "total_words = df[\"tokens\"].apply(len).sum()\n",
    "\n",
    "# iii. Total number of characters (excluding spaces)\n",
    "total_characters = df[\"tokens\"].apply(lambda tokens: sum(len(token) for token in tokens)).sum()\n",
    "\n",
    "# iv. Average Sentence Length (words per sentence)\n",
    "avg_sentence_length = total_words / total_sentences\n",
    "\n",
    "# v. Average Word Length (characters per word)\n",
    "avg_word_length = total_characters / total_words\n",
    "\n",
    "# vi. Type/Token Ratio (TTR)\n",
    "all_tokens = [token for tokens in df[\"tokens\"] for token in tokens]\n",
    "unique_tokens = set(all_tokens)\n",
    "ttr = len(unique_tokens) / total_words\n",
    "\n",
    "# 🧾 Final Output\n",
    "print(\"Corpus Statistics:\")\n",
    "print(f\"1. Total Sentences: {total_sentences}\")\n",
    "print(f\"2. Total Words: {total_words}\")\n",
    "print(f\"3. Total Characters: {total_characters}\")\n",
    "print(f\"4. Average Sentence Length: {avg_sentence_length:.2f} words/sentence\")\n",
    "print(f\"5. Average Word Length: {avg_word_length:.2f} characters/word\")\n",
    "print(f\"6. Type/Token Ratio (TTR): {ttr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a722ee1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96ba848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
