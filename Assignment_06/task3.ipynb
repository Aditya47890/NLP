{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76d4ec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load counts from CSV\n",
    "def load_csv_counts(filename):\n",
    "    counts = {}\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        header = f.readline()\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\",\")\n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "            ngram_str = parts[0].strip().strip('\"')\n",
    "            count_str = parts[1].strip().strip('\"')\n",
    "            try:\n",
    "                count = int(count_str)\n",
    "            except:\n",
    "                continue\n",
    "            ngram = tuple(ngram_str.split())\n",
    "            if len(ngram) == 0:\n",
    "                continue\n",
    "            counts[ngram] = count\n",
    "    return counts\n",
    "\n",
    "# Load trigram and quadrigram\n",
    "tri_counts  = load_csv_counts(r\"C:\\Users\\evilk\\OneDrive\\Desktop\\III YEAR\\LABS\\NLP\\LAB4\\trigram.csv\")\n",
    "quad_counts = load_csv_counts(r\"C:\\Users\\evilk\\OneDrive\\Desktop\\III YEAR\\LABS\\NLP\\LAB4\\quadrigram.csv\")\n",
    "\n",
    "ngram_counts = {3: tri_counts, 4: quad_counts}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9808043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_prob(word, context, counts_dicts, n):\n",
    "    \"\"\"\n",
    "    Returns MLE probability of 'word' given 'context'.\n",
    "    Uses backoff if context not found.\n",
    "    \"\"\"\n",
    "    if n == 1:\n",
    "        total = sum(counts_dicts[3].values())  # fallback: use trigram counts last word frequencies\n",
    "        word_counts = sum(c for g, c in counts_dicts[3].items() if g[-1]==word)\n",
    "        return word_counts / total if total > 0 else 0\n",
    "\n",
    "    ctx = tuple(context[-(n-1):])\n",
    "    ngram = ctx + (word,)\n",
    "    c_ngram = counts_dicts[n].get(ngram, 0)\n",
    "    c_prefix = sum([c for g, c in counts_dicts[n].items() if g[:-1] == ctx])\n",
    "    if c_prefix == 0:\n",
    "        return get_prob(word, context, counts_dicts, n-1)\n",
    "    return c_ngram / c_prefix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "478fd496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_context(counts_dicts, n):\n",
    "    # Choose a context that exists in the n-grams and starts with <s>\n",
    "    candidates = [g[:-1] for g in counts_dicts[n] if g[0] == \"<s>\"]\n",
    "    if candidates:\n",
    "        return list(random.choice(candidates))\n",
    "    else:\n",
    "        return [\"<s>\"] * (n-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c2b341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_greedy_ng(counts_dicts, n, max_len=15):\n",
    "    sentence = get_start_context(counts_dicts, n)\n",
    "    \n",
    "    for _ in range(max_len):\n",
    "        ctx = tuple(sentence[-(n-1):])\n",
    "        candidates_dict = {g[-1]: counts_dicts[n][g] for g in counts_dicts[n] if g[:-1]==ctx}\n",
    "        \n",
    "        if not candidates_dict:\n",
    "            # fallback: pick any last word from trigram\n",
    "            last_words = [g[-1] for g in counts_dicts[3]]\n",
    "            next_word = random.choice(last_words)\n",
    "            sentence.append(next_word)\n",
    "            if next_word == \"</s>\":\n",
    "                break \n",
    "            continue\n",
    "        \n",
    "        # Probabilistic sampling\n",
    "        words, counts = zip(*candidates_dict.items())\n",
    "        probs = [c/sum(counts) for c in counts]\n",
    "        next_word = random.choices(words, probs)[0]\n",
    "        sentence.append(next_word)\n",
    "        if next_word == \"</s>\":\n",
    "            break\n",
    "    return \" \".join(sentence) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20028cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_beam_ng(counts_dicts, n, beam_size=20, max_len=15):\n",
    "    sequences = [(get_start_context(counts_dicts, n), 1.0)]\n",
    "    \n",
    "    for _ in range(max_len):\n",
    "        all_candidates = []\n",
    "        for seq, seq_prob in sequences:\n",
    "            ctx = tuple(seq[-(n-1):])\n",
    "            candidates_dict = {g[-1]: counts_dicts[n][g] for g in counts_dicts[n] if g[:-1]==ctx}\n",
    "            \n",
    "            if not candidates_dict:\n",
    "                # fallback: pick any last word from trigram\n",
    "                last_words = [g[-1] for g in counts_dicts[3]]\n",
    "                next_word = random.choice(last_words)\n",
    "                all_candidates.append((seq+[next_word], seq_prob))\n",
    "                continue\n",
    "            \n",
    "            words, counts = zip(*candidates_dict.items())\n",
    "            probs = [c/sum(counts) for c in counts]\n",
    "            for w, p in zip(words, probs):\n",
    "                all_candidates.append((seq+[w], seq_prob * p))\n",
    "        \n",
    "        all_candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "        sequences = all_candidates[:beam_size]\n",
    "        \n",
    "        if all(seq[-1] == \"</s>\" for seq, _ in sequences):\n",
    "            break\n",
    "    return [\" \".join(seq) for seq, _ in sequences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d5f3419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 3-gram greedy & beam sentences saved.\n",
      "✅ 4-gram greedy & beam sentences saved.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "n_values = [3,4]  # trigram and quadrigram\n",
    "num_sentences = 100\n",
    "\n",
    "for n in n_values:\n",
    "    # Greedy\n",
    "    greedy_sentences = [generate_greedy_ng(ngram_counts, n) for _ in range(num_sentences)]\n",
    "    output_file = f\"C:\\\\Users\\\\evilk\\\\OneDrive\\\\Desktop\\\\III YEAR\\\\LABS\\\\NLP\\\\LAB6\\\\greedy_{n}gram_100.csv\"\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"Sentence\"])\n",
    "        for s in greedy_sentences:\n",
    "            writer.writerow([s])\n",
    "    \n",
    "    # Beam search\n",
    "    beam_sentences = []\n",
    "    while len(beam_sentences) < num_sentences:\n",
    "        seqs = generate_beam_ng(ngram_counts, n, beam_size=20)\n",
    "        beam_sentences.extend(seqs)\n",
    "    beam_sentences = beam_sentences[:num_sentences]\n",
    "    \n",
    "    output_file_beam = f\"C:\\\\Users\\\\evilk\\\\OneDrive\\\\Desktop\\\\III YEAR\\\\LABS\\\\NLP\\\\LAB6\\\\beam_{n}gram_100.csv\"\n",
    "    with open(output_file_beam, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"Sentence\"])\n",
    "        for s in beam_sentences:\n",
    "            writer.writerow([s])\n",
    "    \n",
    "    print(f\"✅ {n}-gram greedy & beam sentences saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bdb8a3",
   "metadata": {},
   "source": [
    "Beam Search is almost always better than Greedy Search for generating high-quality, coherent sentences.\n",
    "Greedy search is faster and simpler, but it often leads to repetitive or nonsensical output because it makes short-sighted decisions. Beam search is a compromise that produces far more fluent and logical sentences by keeping its options open."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa62f519",
   "metadata": {},
   "source": [
    "<!-- Let's prove with a simple example how Greedy Search can fail where Beam Search succeeds.\n",
    "Scenario: We have a bigram model and want to generate a sentence.\n",
    "Vocabulary: <s>, I, am, happy, Sam, </s>\n",
    "Beam Width (k): 2\n",
    "Our Model's Probabilities (designed to trap Greedy Search):\n",
    "| P(w₂ | w₁) | Probability | Note |\n",
    "| :--- | :--- | :--- |\n",
    "| P(I | <s>) | 1.0 | The sentence must start with \"I\" |\n",
    "| P(am | I) | 0.8 | Looks like the best first step |\n",
    "| P(happy | I) | 0.2 | A less likely, but possible first step |\n",
    "| P(Sam | am) | 0.1 | The path after \"am\" leads to a low-probability word |\n",
    "| P(am | happy) | 0.9 | The path after \"happy\" leads to a very high-probability word |\n",
    "| P(</s> | Sam) | 1.0 | The only way to end the \"Sam\" sentence |\n",
    "| P(</s> | am) | 1.0 | The only way to end the \"am\" sentence (after \"happy\") |\n",
    "1. Greedy Search Walkthrough\n",
    "Start: The sequence is <s>.\n",
    "Step 1: The only possible next word is I.\n",
    "Sequence: I. Probability: P(I|<s>) = 1.0.\n",
    "Step 2 (The Greedy Decision):\n",
    "The model compares P(am | I) = 0.8 with P(happy | I) = 0.2.\n",
    "0.8 > 0.2, so the greedy choice is am. It permanently discards the \"happy\" path.\n",
    "Sequence: I am. Cumulative Probability: 1.0 * 0.8 = 0.8.\n",
    "Step 3: From \"am\", the only option is \"Sam\".\n",
    "Sequence: I am Sam. Cumulative Probability: 0.8 * P(Sam | am) = 0.8 * 0.1 = 0.08.\n",
    "Step 4: From \"Sam\", the only option is </s>.\n",
    "Final Sequence: I am Sam </s>. Final Probability: 0.08.\n",
    "Result: Greedy Search generates \"I am Sam\" with a probability of 0.08.\n",
    "2. Beam Search Walkthrough (Beam Width = 2)\n",
    "Start: The sequence is <s>.\n",
    "Step 1 (Expand):\n",
    "Possible next word is I.\n",
    "Hypotheses: [ (\"I\", P=1.0) ]\n",
    "Step 2 (Expand):\n",
    "From \"I\", we generate two new candidate sequences:\n",
    "Candidate A: I am. Probability = P(I) * P(am|I) = 1.0 * 0.8 = 0.8\n",
    "Candidate B: I happy. Probability = P(I) * P(happy|I) = 1.0 * 0.2 = 0.2\n",
    "Our candidate list is [ (\"I am\", 0.8), (\"I happy\", 0.2) ].\n",
    "Step 2 (Prune):\n",
    "We sort the candidates by probability: 0.8 > 0.2.\n",
    "Our beam width is k=2, so we keep both.\n",
    "Current Beam: Hypothesis 1: (\"I am\", 0.8), Hypothesis 2: (\"I happy\", 0.2)\n",
    "Step 3 (Expand):\n",
    "Expand Hypothesis 1 (\"I am\"):\n",
    "Candidate C: I am Sam. Probability = P(\"I am\") * P(Sam|am) = 0.8 * 0.1 = 0.08\n",
    "Expand Hypothesis 2 (\"I happy\"):\n",
    "Candidate D: I happy am. Probability = P(\"I happy\") * P(am|happy) = 0.2 * 0.9 = 0.18\n",
    "Our new candidate list is [ (\"I am Sam\", 0.08), (\"I happy am\", 0.18) ].\n",
    "Step 3 (Prune):\n",
    "We sort the candidates by probability: 0.18 > 0.08.\n",
    "We keep the top k=2.\n",
    "Current Beam: Hypothesis 1: (\"I happy am\", 0.18), Hypothesis 2: (\"I am Sam\", 0.08)\n",
    "This is the key moment! The initially less-likely \"happy\" path has now produced a more probable overall sequence and has been promoted to the top of our beam. The greedy path is now in second place.\n",
    "Step 4 (Finalize):\n",
    "Both hypotheses will now be terminated with </s>.\n",
    "Hypothesis 1 becomes \"I happy am </s>\" with P=0.18.\n",
    "Hypothesis 2 becomes \"I am Sam </s>\" with P=0.08.\n",
    "The top sequence in the final beam is \"I happy am\".\n",
    "Result: Beam Search generates \"I happy am\" with a probability of 0.18.\n",
    "Conclusion of the Proof\n",
    "Greedy Search found the sentence \"I am Sam\" with a total probability of 0.08.\n",
    "Beam Search found the sentence \"I happy am\" with a total probability of 0.18.\n",
    "Since 0.18 > 0.08, Beam Search found a more probable, and therefore mathematically \"better,\" sentence. It succeeded because it didn't immediately discard the \"happy\" path just because it was less likely at the first step. By keeping it as a possibility, it discovered that this path ultimately led to a much more likely outcome. This proves the superiority of Beam Search in avoiding local maxima and finding more globally optimal solutions. -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
